# LLM as a Judge — Daily Report

Report date: 2026-02-13 (UTC)
Coverage window: last 1 days

Query:
`ti:"LLM as a judge" OR abs:"LLM as a judge" OR ti:"LLM-as-a-judge" OR abs:"LLM-as-a-judge" OR ti:"large language model as a judge" OR abs:"large language model as a judge" OR ti:"LLM judge" OR abs:"LLM judge" OR ti:"LLM-based evaluation" OR abs:"LLM-based evaluation" OR ti:"LLM evaluation" OR abs:"LLM evaluation"`

Total papers: 4

## Papers

### Asynchronous Verified Semantic Caching for Tiered LLM Architectures (2602.13165v1)

Authors: Asmit Kumar Singh, Haozhe Wang, Laxmi Naga Santosh Attaluri, et al.
Published: 2026-02-13
Updated: 2026-02-13
Categories: cs.IR, cs.AI
Link: [arXiv](http://arxiv.org/abs/2602.13165v1)

Abstract: Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency.

Summary:
Purpose: The paper aims to reduce inference cost and latency in large language models by introducing an asynchronous verified semantic caching policy for tiered architectures.
Method: The proposed approach, called Krites, uses a static cache and dynamically invokes a language model judge to verify whether static responses are acceptable for new prompts that fall just below the static threshold.
Results: Krites increases the fraction of requests served with curated static answers by up to 3.9 times for conversational traffic and search-style queries relative to tuned baselines, without changing critical path latency.
Tags: Robustness And Sensitivity, Benchmark And Dataset Creation

### SCOPE: Selective Conformal Optimized Pairwise LLM Judging (2602.13110v2)

Authors: Sher Badshah, Ali Emami, Hassan Sajjad
Published: 2026-02-13
Updated: 2026-02-19
Categories: cs.CL, cs.AI
Link: [arXiv](http://arxiv.org/abs/2602.13110v2)

Abstract: Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE (Selective Conformal Optimized Pairwise Evaluation), a framework for selective pairwise judging with finite-sample statistical guarantees. Under exchangeability, SCOPE calibrates an acceptance threshold such that the error rate among non-abstained judgments is at most a user-specified level $α$. To provide SCOPE with a bias-neutral uncertainty signal, we introduce Bidirectional Preference Entropy (BPE), which queries the judge under both response positions, aggregates the implied preference probabilities to enforce invariance to response order, and converts the aggregated probability into an entropy-based uncertainty score. Across MT-Bench, RewardBench, and Chatbot Arena, BPE improves uncertainty quality over standard confidence proxies, providing a stronger selection signal that enables SCOPE to consistently meet the target risk level while retaining good coverage across judge scales. In particular, at $α= 0.10$, SCOPE consistently satisfies the risk bound across all benchmarks and judge scales (empirical risk $\approx 0.097$ to $0.099$), while retaining substantial coverage, reaching $0.89$ on RewardBench with Qwen-14B and $0.98$ on RewardBench with Qwen-32B. Compared to naïve baselines, SCOPE accepts up to $2.4\times$ more judgments on MT-Bench with Qwen-7B under the same target risk constraint, demonstrating that BPE enables reliable and high-coverage LLM-based evaluation.

Summary:
Purpose: The paper proposes a framework called SCOPE for selective pairwise judging using large language models (LLMs) as judges to replace human preference labels in pairwise evaluation with finite-sample statistical guarantees.
Method: To achieve this, the authors introduce Bidirectional Preference Entropy (BPE), which provides a bias-neutral uncertainty signal by querying the judge under both response positions and aggregating the implied preference probabilities.
Results: The proposed framework, SCOPE, consistently meets the target risk level while retaining good coverage across judge scales, demonstrating its effectiveness in reliable and high-coverage LLM-based evaluation with significant improvements over naïve baselines.
Tags: Judge Reliability And Calibration, Judge Prompting Protocols

### iRULER: Intelligible Rubric-Based User-Defined LLM Evaluation for Revision (2602.12779v1)

Authors: Jingwen Bai, Wei Soon Cheong, Philippe Muller, et al.
Published: 2026-02-13
Updated: 2026-02-13
Categories: cs.HC
Link: [arXiv](http://arxiv.org/abs/2602.12779v1)

Abstract: Large Language Models (LLMs) have become indispensable for evaluating writing. However, text feedback they provide is often unintelligible, generic, and not specific to user criteria. Inspired by structured rubrics in education and intelligible AI explanations, we propose iRULER following identified design guidelines to \textit{scaffold} the review process by \textit{specific} criteria, providing \textit{justification} for score selection, and offering \textit{actionable} revisions to target different quality levels. To \textit{qualify} user-defined criteria, we recursively used iRULER with a rubric-of-rubrics to iteratively \textit{refine} rubrics. In controlled experiments on writing revision and rubric creation, iRULER most improved validated LLM-judged review scores and was perceived as most helpful and aligned compared to read-only rubric and text-based LLM feedback. Qualitative findings further support how iRULER satisfies the design guidelines for user-defined feedback. This work contributes interactive rubric tools for intelligible LLM-based review and revision of writing, and user-defined rubric creation.

Summary:
Purpose: The purpose of the paper is to propose a novel approach called iRULER, which aims to improve the evaluation and revision process of Large Language Models (LLMs) by providing intelligible and user-defined feedback.
Method: Method: The method used in this study involves designing iRULER based on identified guidelines that scaffold the review process with specific criteria, justification for score selection, and actionable revisions, and then testing it through controlled experiments on writing revision and rubric creation.
Results: Results: The results of the study show that iRULER significantly improved validated LLM-judged review scores, was perceived as most helpful and aligned, and satisfied the design guidelines for user-defined feedback, contributing to the development of interactive rubric tools for intelligible LLM-based review and revision.
Tags: Judge Prompting Protocols, Domain-Specific Judging

### CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation (2602.12639v1)

Authors: Yiran Rex Ma, Yuxiao Ye, Huiyuan Xie
Published: 2026-02-13
Updated: 2026-02-13
Categories: cs.CL
Link: [arXiv](http://arxiv.org/abs/2602.12639v1)

Abstract: Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to improve stylistic quality, a crucial first step is to establish a reliable evaluation method. However, having legal experts manually develop such a metric is impractical, as the implicit stylistic requirements in legal writing practice are difficult to formalise into explicit rubrics. Meanwhile, existing automatic evaluation methods also fall short: reference-based metrics conflate semantic accuracy with stylistic fidelity, and LLM-as-a-judge evaluations suffer from opacity and inconsistency. To address these challenges, we introduce CLASE (Chinese LegAlese Stylistic Evaluation), a hybrid evaluation method that focuses on the stylistic performance of legal text. The method incorporates a hybrid scoring mechanism that combines 1) linguistic feature-based scores and 2) experience-guided LLM-as-a-judge scores. Both the feature coefficients and the LLM scoring experiences are learned from contrastive pairs of authentic legal documents and their LLM-restored counterparts. This hybrid design captures both surface-level features and implicit stylistic norms in a transparent, reference-free manner. Experiments on 200 Chinese legal documents show that CLASE achieves substantially higher alignment with human judgments than traditional metrics and pure LLM-as-a-judge methods. Beyond improved alignment, CLASE provides interpretable score breakdowns and suggestions for improvements, offering a scalable and practical solution for professional stylistic evaluation in legal text generation (Code and data for CLASE is available at: https://github.com/rexera/CLASE).

Summary:
Purpose: The purpose of this paper is to introduce CLASE, a hybrid method for evaluating the stylistic quality of Chinese legal text generated by large language models, which aims to address the limitations of existing evaluation methods.
Method: The method used in CLASE combines linguistic feature-based scores and experience-guided LLM-as-a-judge scores, learned from contrastive pairs of authentic legal documents and their LLM-restored counterparts, to capture both surface-level features and implicit stylistic norms.
Results: The results of the experiments show that CLASE achieves substantially higher alignment with human judgments than traditional metrics and pure LLM-as-a-judge methods, providing interpretable score breakdowns and suggestions for improvements in legal text generation.
Tags: Metrics And Scoring Methods, Judge Reliability And Calibration
